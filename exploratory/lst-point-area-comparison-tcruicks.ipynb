{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Detection of Crop Stress From Thermal Infrared Imagery\n",
    "![Hydrosat](https://uploads-ssl.webflow.com/61e4aee27ac4a95d23ab9609/61e9d6f5d6578e8c7c0cca8f_solutions-thermal-min.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/pstrmbpn6t75t6hdl9_v8_8w0000gn/T/ipykernel_3538/965320236.py:3: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pystac\n",
    "import requests\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from distutils.command import sdist\n",
    "from matplotlib import pyplot as plt\n",
    "from pyproj.crs import CRS\n",
    "from pystac_client import Client\n",
    "from pprint import pprint\n",
    "from shapely.geometry import box, mapping, Point, Polygon\n",
    "\n",
    "# Project specific packages\n",
    "from FH_Hydrosat import FH_StackedDataset\n",
    "from FH_Hydrosat import FH_Hydrosat\n",
    "from herbie import FastHerbie\n",
    "\n",
    "os.environ['USE_PYGEOS'] = '0'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS.  No user editing is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "def create_clip_polygon(geom, ds, buffer):\n",
    "    \"\"\"\n",
    "    Create a polygon that we will use for clipping the big dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    geom: dict\n",
    "        Dictionary of lat and lon of center point of AOI.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    poly: dataframe\n",
    "        Contains geometry of a square to be used for clipping.\n",
    "    \"\"\"\n",
    "    # Using the point coords defined earlier, create a df with the point geometry.\n",
    "    p_geom = Point(geom['coordinates'][0], geom['coordinates'][1])\n",
    "    point_df = gpd.GeoDataFrame({'geometry':[p_geom]}, crs=CRS.from_epsg(4326))\n",
    "\n",
    "    # Define a buffer size (for each side of the point.\n",
    "    # Reproject the point df and create the new polygon.\n",
    "    raster_crs = CRS.from_wkt(ds.spatial_ref.crs_wkt)\n",
    "    buffer_dist = buffer # 1km in local UTM zone\n",
    "\n",
    "    # create a square buffer\n",
    "    poly_df = point_df.to_crs(raster_crs).buffer(buffer_dist, cap_style = 3) \n",
    "\n",
    "    return(poly_df)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "def stac_tile_search(collection, geom, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Log into STAC and search for a specified image collection.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    collection: list\n",
    "        List of tiles found in STAC.\n",
    "\n",
    "    geom: \n",
    "        Point location to search.\n",
    "\n",
    "    start_date, end_date: str\n",
    "        Dates to search between.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    \"\"\"\n",
    "    search = catalog.search(\n",
    "        collections = collection,\n",
    "        intersects = geom,\n",
    "        datetime = [start_date, end_date],\n",
    "        max_items = 500\n",
    "    )\n",
    "\n",
    "    #items = list(search.items()) # for pystac-client >= 0.4.0\n",
    "    found_items = list(search.get_all_items()) # for pystac-client < 0.4.0\n",
    "\n",
    "    # Filter out only the newest version of MODIS.\n",
    "    if collection == 'prepped_inputs_mcd43a4':\n",
    "        version_str = '061'\n",
    "        new_list = [i for i in found_items if version_str in i.id]\n",
    "        found_items = new_list\n",
    "\n",
    "    found_items.reverse() # make the results ascending in time\n",
    "\n",
    "    num_tiles = len(found_items)\n",
    "    print (\"Searching {} colllection .... images available: {}\\n\".format(collection, num_tiles))\n",
    "\n",
    "    return (found_items, num_tiles)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "def create_aoi_image_stack(items, num_tiles, geom, asset, buffer):\n",
    "    '''\n",
    "    Gets images, stacks them and sorts them by date and clips them down to a smaller\n",
    "    AOI size.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    itmes: list \n",
    "        List of available images.\n",
    "    num_tiles: int\n",
    "        Number of tiles to download (days)\n",
    "    asset: str\n",
    "        Name of asset to get.\n",
    "    geom: x,y coords\n",
    "        Coordinates around which to build a polygon\n",
    "    buffer: int\n",
    "        Buffer around the x,y for creating the AOI rectangele.  In meters.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    aoi_stack_ds: dataset as FH_StackedDataset object.\n",
    "        Stack of images clipped to AOI.\n",
    "\n",
    "    '''\n",
    "    images = FH_Hydrosat(items[:num_tiles], asset=asset)\n",
    "\n",
    "    # Stacks all the files into a dataset and then return a FH_StackedDataset object.\n",
    "    stacked_images = images.stack()\n",
    "    # Sort the dataset by time.\n",
    "    ds = stacked_images.ds.sortby('time')\n",
    "\n",
    "    # Create polygon Area of Interest (AOI for which to sample.).\n",
    "    clip_poly_df = create_clip_polygon(geom, ds, buffer=buffer)\n",
    "    # Use AOI polygon to clip the dataset dwon to size and make it into a FH_StackedDataset object.\n",
    "    clipped = FH_StackedDataset(ds.rio.clip(clip_poly_df.geometry))\n",
    "    aoi_stack_ds = clipped.ds\n",
    "\n",
    "    return (aoi_stack_ds)\n",
    "\n",
    " # ---------------------------------------------------------------------------------   \n",
    "\n",
    "def extract_time_series(items, bbox, tol, var_name, asset, band, pad):\n",
    "    '''\n",
    "    Uses FH_Hydrosat class method point_time_series_from_items()\n",
    "    to extract only a time-series.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    items: list\n",
    "        Image items returned from STAC search.\n",
    "    bbox: \n",
    "        Bounding box of coordinates for seacrh site.\n",
    "    tol: int\n",
    "        A search parameter in meters for finding point data.\n",
    "    var_name: str\n",
    "        Dataframe column name for data extracted.\n",
    "    asset: str\n",
    "        Search parameter for type of asset to be searched.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lst_df: dataframe\n",
    "        Dataframe containing date time series.\n",
    "    '''\n",
    "    # Sample the LST items.\n",
    "    lst_res = FH_Hydrosat(items, asset=asset)\n",
    "    ###########################\n",
    "    images = FH_Hydrosat(items[:num_tiles], asset=asset)\n",
    "\n",
    "    # Stacks all the files into a dataset and then returns a FH_StackedDataset object.\n",
    "    stacked_images = images.stack()\n",
    "    stacked_images.ds.sortby('time')\n",
    "    # Sort the dataset by time.\n",
    "    ds = stacked_images.ds.sortby('time')\n",
    "\n",
    "    # Create polygon Area of Interest (AOI for which to sample.).\n",
    "    clip_poly_df = create_clip_polygon(geom, ds)\n",
    "    # Use AOI polygon to clip the dataset dwon to size and make it into a FH_StackedDataset object.\n",
    "    clipped = FH_StackedDataset(ds.rio.clip(clip_poly_df.geometry))\n",
    "    aoi_stack_ds = clipped.ds\n",
    "    ###########################\n",
    "\n",
    "    # Set the point for time-series extraction.\n",
    "    point_wgs84 = Point(box(*bbox).centroid.x, box(*bbox).centroid.y)\n",
    "    \n",
    "    # Extract time-series data using function.\n",
    "    band = int(band) # band needs to be an int because it comes in as a string.\n",
    "    lst_k  = lst_res.point_time_series_from_items(point_wgs84, tol=tol, nproc=6, band=band, pad=pad) \n",
    "\n",
    "    # Create a datetime dataframe\n",
    "    lst_dt = lst_res.datetime\n",
    "    lst_df = pd.DataFrame({var_name: lst_k,\n",
    "                       'datetime': pd.to_datetime(lst_dt)}).sort_values(by='datetime')\n",
    "    \n",
    "    # Get the date in the correct/consistent format.\n",
    "    lst_df['date'] = [t.to_pydatetime().strftime('%Y-%m-%d') for t in lst_df['datetime']]\n",
    "    lst_df['date'] = pd.to_datetime(lst_df['date'])\n",
    "    lst_df.drop(columns='datetime', inplace=True)\n",
    "    lst_df.set_index('date', drop=True, inplace=True)\n",
    "    \n",
    "    return (lst_df)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "def get_hrrr_point_data(lat, lon, start, days):\n",
    "    ''' \n",
    "    Fetch met data from the HRRR model system.\n",
    "    Herbie package needs to be installed:\n",
    "    https://herbie.readthedocs.io/en/stable/\n",
    "    ${HOME}/.config/herbie/config.toml\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    lat, lon: float\n",
    "        Coords from which to pull grid cell data. \n",
    "    start: str\n",
    "        This is the start date for which data will be retrieved.\n",
    "    days: int\n",
    "        Number of days of data to retrieve.\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    ds_point: xarray dataset\n",
    "        Met data for specified point.\n",
    "    '''\n",
    " \n",
    "    # Create a range of dates\n",
    "    DATES = pd.date_range(\n",
    "        start=start,\n",
    "        periods=days,\n",
    "        freq=\"1D\",\n",
    "    )\n",
    "\n",
    "    # Define forecast lead time (or analysis).\n",
    "    fxx = range(0, 1)\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # For long time-series analyses\n",
    "    # -----------------------------------------------\n",
    "    FH = FastHerbie(DATES, model=\"hrrr\", fxx=fxx)\n",
    "    FH.download(\"TMP:2 m\")\n",
    "    ds = FH.xarray(\"TMP:2 m\", remove_grib=False)\n",
    "    # -----------------------------------------------\n",
    "    # For real-time fetching of HRRR data.\n",
    "    # -----------------------------------------------\n",
    "    # Make FastHerbie Object.\n",
    "    # FH = FastHerbie(DATES, model=\"hrrr\", fxx=fxx)\n",
    "    # Read a subset of the data with xarray.\n",
    "    # ds = FH.xarray(\"TMP:2 m\", remove_grib=False)\n",
    "    # -----------------------------------------------\n",
    "\n",
    "    # Get data values nearest single point\n",
    "    ds_point = ds.herbie.nearest_points(points=(lon, lat))\n",
    "   \n",
    "    return (ds_point)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to STAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open credentials file.\n",
    "with open('../secrets/creds.json') as f:\n",
    "    creds = json.loads(f.read())\n",
    "\n",
    "# Endecode the `username:password` combination \n",
    "# and use it to authorize access to the STAC API given by the `cat_url` \n",
    "# endpoint.userpass = f\"{creds['username']}:{creds['password']}\"\n",
    "userpass = f\"{creds['username']}:{creds['password']}\"\n",
    "b64 = base64.b64encode(userpass.encode()).decode()\n",
    "headers = {'Authorization':'Basic ' + b64}\n",
    "\n",
    "cat_url = 'https://fusion-stac.hydrosat.com'\n",
    "catalog = Client.open(cat_url, headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up analysis.  User edits required in cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# USER EDITS REQUIRED -------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Location for time-series data extraction.\n",
    "lat = 42.0   \n",
    "lon = -93.7  \n",
    "\n",
    "# Define size of AOI.\n",
    "#    Length    x    Width \n",
    "# (buffer * 2) x (buffer * 2)\n",
    "buffer = 250\n",
    "\n",
    "# Specify dates & hour for LST analysis.\n",
    "start = \"2020-04-01\"  \n",
    "end = \"2020-10-30\"  \n",
    "hr_s = \"00:00:00\"  \n",
    "hr_e = '23:59:59'\n",
    "# ---------------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Create dict of coords.  Will be used to create a polygon for our AOI.\n",
    "geom = {'type': 'Point', 'coordinates': [lon, lat]} \n",
    "\n",
    "# We need the total num of days for the analysis to get hrrr data.\n",
    "f = start.split(\"-\")\n",
    "l = end.split(\"-\")\n",
    "\n",
    "f_dt = date(int(f[0]), int(f[1]), int(f[2]))  \n",
    "l_dt = date(int(l[0]), int(l[1]), int(l[2]))  \n",
    "num_days = (l_dt - f_dt)\n",
    "num_days = num_days.days\n",
    "\n",
    "# Need to do some formating for various requirements.\n",
    "hr_s_form = \"T{}Z\".format(hr_s)\n",
    "hr_e_form = \"T{}Z\".format(hr_e)\n",
    "start_date = start + hr_s_form\n",
    "end_date = end + hr_e_form\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Fused LST data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching starfm_predictions_modis_landsat colllection .... images available: 157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collection to search for.\n",
    "collection = 'starfm_predictions_modis_landsat'\n",
    "asset = 'lst'\n",
    "\n",
    "# Search STAC for available images.\n",
    "(found_items, num_tiles) = stac_tile_search(collection, geom, start_date, end_date)\n",
    "\n",
    "# Extract data. \n",
    "(aoi_lst_da) = create_aoi_image_stack(found_items, num_tiles, geom, asset, buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_lst_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean of all pixels for each time-step.\n",
    "aoi_mean_lst_da = aoi_lst_da.isel(band=0).mean(dim=[\"x\", \"y\"])\n",
    "\n",
    "# Convert to dataframe.\n",
    "aoi_mean_lst_df = aoi_mean_lst_da.to_dataframe(name='starfm_lst')\n",
    "# Change date format to be consistent.\n",
    "aoi_mean_lst_df.index = pd.to_datetime(aoi_mean_lst_df.index)\n",
    "aoi_mean_lst_df.index = aoi_mean_lst_df.index.strftime('%Y-%m-%d')\n",
    "\n",
    "# Create df with a complete list of dates.\n",
    "days = pd.date_range(start, end)\n",
    "dates_df = pd.DataFrame({'time': days})\n",
    "dates_df['time'] = pd.to_datetime(dates_df.time)\n",
    "dates_df.set_index('time', inplace=True)\n",
    "# Change date format to be consistent.\n",
    "dates_df.index = dates_df.index.strftime('%Y-%m-%d')\n",
    "\n",
    "# Merge each df into master dataframe.\n",
    "# Merge on index (date) and keep all rows from both dfs (inner join).\n",
    "lst_df = pd.merge(\n",
    "    dates_df, aoi_mean_lst_df, \n",
    "    left_index=True, right_index=True, how = 'outer')  \n",
    "\n",
    "# Interpolate missing values.\n",
    "interpd_aoi_lst_df = lst_df.interpolate(method='linear', inplace=False)\n",
    "# Drop uneeded columns.\n",
    "interpd_aoi_lst_df.drop(columns=['band', 'spatial_ref'], inplace=True)\n",
    "\n",
    "# Plot up a time series of of the daily AOI mean LST.\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax = plt.plot(interpd_aoi_lst_df.starfm_lst, marker='o', markersize=4, c='blue')\n",
    "\n",
    "plt.title('AOI Mean of Fused LST Time Series')\n",
    "plt.grid(True)\n",
    "plt.ylabel('Fused LST [K] (20 m)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get HRRR 2-m Temperature data and put it in it's own dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the hrrr data.\n",
    "hrrr = get_hrrr_point_data(lat, lon, start, num_days)\n",
    "\n",
    "# Convert to dataframe and clean it up.\n",
    "# Get a dataset of point hrrr and convert to dataframe for easier use. \n",
    "hrrr_df = hrrr.to_dataframe()\n",
    "\n",
    "# Make date consistent in format.\n",
    "hrrr_df.reset_index(inplace=True)\n",
    "hrrr_df['date'] = pd.to_datetime(hrrr_df['time'].dt.date)\n",
    "\n",
    "# Set the index to date just like the other dataframes.\n",
    "hrrr_df.set_index('time', inplace=True)\n",
    "# Change date format to be consistent.\n",
    "hrrr_df.index = hrrr_df.index.strftime('%Y-%m-%d')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we'll calculate CATD using the LST and 2-m Temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATD will be calculated as:\n",
    "# (CATD = LST - 2 m Temperature)\n",
    "\n",
    "# Calculate CATD.\n",
    "catd_df = pd.DataFrame()\n",
    "catd_df['catd'] = interpd_aoi_lst_df['starfm_lst'].sub(hrrr_df['t2m'])\n",
    "\n",
    "# Plot up a time series of of the daily AOI mean LST.\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax = plt.plot(catd_df, marker='s', markersize=8, c='green')\n",
    "\n",
    "plt.title('CATD Time Series for All Pixels')\n",
    "plt.grid(True)\n",
    "plt.ylabel('CATD (20 m)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface reflectance is extracted for and NDVI is calculated.\n",
    "    \n",
    "# Search STAC for available images from collection..\n",
    "collection = \"starfm_predictions_modis_s2\"\n",
    "(found_items, num_tiles) = stac_tile_search(collection, geom, start_date, end_date)\n",
    "\n",
    "# Extract red band data from aoi.. \n",
    "asset='surface_reflectance_red'\n",
    "(aoi_red_da) = create_aoi_image_stack(found_items, num_tiles, geom, asset, buffer)\n",
    "\n",
    "# Extract nir band data from aoi. \n",
    "asset='surface_reflectance_nir'\n",
    "(aoi_nir_da) = create_aoi_image_stack(found_items, num_tiles, geom, asset, buffer)\n",
    "\n",
    "# Get mean of all pixels for each time-step.\n",
    "aoi_mean_red_da = aoi_red_da.isel(band=0).mean(dim=[\"x\", \"y\"])\n",
    "aoi_mean_nir_da = aoi_nir_da.isel(band=0).mean(dim=[\"x\", \"y\"])\n",
    "\n",
    "# Calculate ndvi.\n",
    "ndvi_da = (aoi_mean_nir_da - aoi_mean_red_da)  / (aoi_mean_nir_da + aoi_mean_red_da)\n",
    "\n",
    "# Create our own dataframe instead of using to_dataframe which takes\n",
    "# forever dealing with the dask graphs.\n",
    "# ndvi_vals = ndvi_da.values()\n",
    "# ndvi_dates = ndvi_da.time().values\n",
    "# ndvi_df = pd.DataFrame({\"time\": ndvi_dates, \"ndvi\": ndvi_vals})\n",
    "\n",
    "\n",
    "# Convert to dataaframe\n",
    "ndvi_df = ndvi_da.to_dataframe(name='ndvi')\n",
    "\n",
    "# Change date format to be consistent.\n",
    "# Set the index to date just like the other dataframes.\n",
    "\n",
    "# Change date format to be consistent.\n",
    "ndvi_df.index = ndvi_df.index.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_red_da.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Mean CATD and Mean NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot up a time series of of the daily AOI mean LST.\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "# Plot on 2 y-axes.\n",
    "ax2 = ax1.twinx()  \n",
    "\n",
    "ax1.plot(catd_df.index, catd_df.catd, marker='s', markersize=8, c='green', label='CATD')\n",
    "ax2.plot(ndvi_df.index, ndvi_df.ndvi, marker='s', markersize=8, c='blue', label='NDVI')\n",
    "\n",
    "#ax1.set_ylabel(\"Fused CATD\", color='green', fontsize=14)\n",
    "#ax2.set_ylabel(label=label, color='blue', fontsize=14)\n",
    "ax1.set(ylim=(-25, 25), ylabel=\"CATD\")\n",
    "ax2.set( ylabel=\"NDVI\")\n",
    "\n",
    "ax1.grid(True) \n",
    "\n",
    "plt.title('AOI Mean CATD & Mean NDVI')\n",
    "plt.xticks(rotation=45)\n",
    "ax1.set_xticklabels(ax1.get_xticks(), rotation = 45)\n",
    "\n",
    "ax1.legend(loc=2)\n",
    "ax2.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CWSI-EB (Crop Water Stress Index) - Katimbo et al (2022) in Agricultural Water Management.\n",
    "\n",
    "CWSI = ((Tc - Ta)a - (Tcl - Ta)U) / ((Tcu - Ta)L - (Tcl - Ta)L)\n",
    "\n",
    "    Tc = canopy Temp (fused LST)\n",
    "    Ta = ambient air temp (HRRR 2mT)\n",
    "    Tcl = Tc of well transpiring veg\n",
    "    Tcu = Tc of non-transpiring veg\n",
    "    \n",
    "    (Tcl - Ta)L = A + B * VPD\n",
    "\n",
    "        VPD = e - es\n",
    "        e = 6.11 × 10 exp(7.5 × Td / 237.3 + Td )\n",
    "        es = 6.11 × 10 exp(7.5 × T / 237.3 + T )\n",
    "        A = intercept of a regression of (Tc - Ta) and VPD\n",
    "        B = slope of a regression of (Tc - Ta) and VPD\n",
    "\n",
    "    (Tc - Ta)a = A + B * VPG\n",
    "    \n",
    "        VPG = Ta - (Ta + A)\n",
    "        A = intercept of a regression of (Tc - Ta) and VPD\n",
    "        B = slope of a regression of (Tc - Ta) and VPD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_canopy = lst_df\n",
    "t_air = hrrr_df\n",
    "\n",
    "t_cl = lst_aoi_da.max()\n",
    "t_cu = lst_aoi_da.min()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrosat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dd708af889ccc3bd37f2e364356efaa19b67cae4fd5543545686cdc77cf6309"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
